{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_grad_cam import (\n",
    "    AblationCAM,\n",
    "    EigenCAM,\n",
    "    EigenGradCAM,\n",
    "    FullGrad,\n",
    "    GradCAM,\n",
    "    GradCAMPlusPlus,\n",
    "    GuidedBackpropReLUModel,\n",
    "    LayerCAM,\n",
    "    ScoreCAM,\n",
    "    XGradCAM,\n",
    ")\n",
    "from pytorch_grad_cam.utils.image import preprocess_image, show_cam_on_image\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config(object):\n",
    "    use_cude: bool = True\n",
    "    image_path: dir = \"./test_images/\"\n",
    "    aug_smooth: bool = True\n",
    "    eigen_smooth: bool = True\n",
    "    method: str = \"gradcam\"\n",
    "\n",
    "\n",
    "def reshape_transform(tensor, height=14, width=14):\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, tensor.size(2))\n",
    "\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"python vit_gradcam.py -image-path <path_to_image>\n",
    "    Example usage of using cam-methods on a VIT network.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    args = Config()\n",
    "    methods = {\n",
    "        \"gradcam\": GradCAM,\n",
    "        \"scorecam\": ScoreCAM,\n",
    "        \"gradcam++\": GradCAMPlusPlus,\n",
    "        \"ablationcam\": AblationCAM,\n",
    "        \"xgradcam\": XGradCAM,\n",
    "        \"eigencam\": EigenCAM,\n",
    "        \"eigengradcam\": EigenGradCAM,\n",
    "        \"layercam\": LayerCAM,\n",
    "        \"fullgrad\": FullGrad,\n",
    "    }\n",
    "\n",
    "    if args.method not in list(methods.keys()):\n",
    "        raise Exception(f\"method should be one of {list(methods.keys())}\")\n",
    "\n",
    "    model = torch.hub.load(\n",
    "        \"facebookresearch/deit:main\", \"deit_tiny_patch16_224\", pretrained=True\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    if args.use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    target_layers = [model.blocks[-1].norm1]\n",
    "\n",
    "    if args.method not in methods:\n",
    "        raise Exception(f\"Method {args.method} not implemented\")\n",
    "\n",
    "    cam = methods[args.method](\n",
    "        model=model,\n",
    "        target_layers=target_layers,\n",
    "        use_cuda=args.use_cuda,\n",
    "        reshape_transform=reshape_transform,\n",
    "    )\n",
    "\n",
    "    rgb_img = cv2.imread(args.image_path, 1)[:, :, ::-1]\n",
    "    rgb_img = cv2.resize(rgb_img, (224, 224))\n",
    "    rgb_img = np.float32(rgb_img) / 255\n",
    "    input_tensor = preprocess_image(rgb_img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "    # If None, returns the map for the highest scoring category.\n",
    "    # Otherwise, targets the requested category.\n",
    "    target_category = None\n",
    "\n",
    "    # AblationCAM and ScoreCAM have batched implementations.\n",
    "    # You can override the internal batch size for faster computation.\n",
    "    cam.batch_size = 32\n",
    "\n",
    "    grayscale_cam = cam(\n",
    "        input_tensor=input_tensor,\n",
    "        target_category=target_category,\n",
    "        eigen_smooth=args.eigen_smooth,\n",
    "        aug_smooth=args.aug_smooth,\n",
    "    )\n",
    "\n",
    "    # Here grayscale_cam has only one image in the batch\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam)\n",
    "    cv2.imwrite(f\"{args.method}_cam.jpg\", cam_image)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
